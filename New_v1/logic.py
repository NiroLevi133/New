from __future__ import annotations
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ×™×™×¦×•× ×›×œ ×”×¤×•× ×§×¦×™×•×ª ×•×”×§×‘×•×¢×™× ×”×“×¨×•×©×™× ×œ-main.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

__all__ = [
    # ×¤×•× ×§×¦×™×•×ª ×¢×™×‘×•×“ ×§×‘×¦×™×
    'load_excel_flexible',
    'load_mobile_contacts',
    'load_excel',
    
    # ×¤×•× ×§×¦×™×•×ª ×”×ª×××•×ª
    'top_matches',
    'full_score',
    'process_matching_results',
    'compute_best_scores',
    'extract_relevant_guest_details',
    'extract_smart_fields',  # ğŸ”¥ ×—×“×©
    
    # ×¤×•× ×§×¦×™×•×ª ×‘×“×™×§×”
    'validate_dataframes',
    'is_user_authorized',
    
    # ×¤×•× ×§×¦×™×•×ª ×™×™×¦×•×
    'to_buf',
    'create_contacts_template',
    'create_guests_template',
    
    # ×¤×•× ×§×¦×™×•×ª ×¢×–×¨
    'format_phone',
    'normalize',
    'reason_for',
    
    # ×§×‘×•×¢×™×
    'NAME_COL',
    'PHONE_COL',
    'COUNT_COL',
    'SIDE_COL',
    'GROUP_COL',
    'AUTO_SCORE',
    'AUTO_SELECT_TH',
    'MIN_SCORE_DISPLAY',
    'MAX_DISPLAYED',
    'FIELD_PRIORITY',  # ğŸ”¥ ×—×“×©
]

import os, re, logging, json
from io import BytesIO
from typing import List, Set, Dict, Optional

import pandas as pd
import unidecode
from rapidfuzz import fuzz, distance

# Google Sheets via ADC (Cloud Run Service Account)
try:
    import google.auth
    import gspread
    GOOGLE_AVAILABLE = True
except ImportError:
    GOOGLE_AVAILABLE = False
    logging.warning("Google auth not available - using local files only")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ×§×‘×•×¢×™× â”€â”€â”€â”€â”€â”€â”€â”€â”€
NAME_COL          = "×©× ××œ×"
PHONE_COL         = "××¡×¤×¨ ×¤×œ××¤×•×Ÿ"
COUNT_COL         = "×›××•×ª ××•×–×× ×™×"
SIDE_COL          = "×¦×“"
GROUP_COL         = "×§×‘×•×¦×”"

AUTO_SCORE        = 100
AUTO_SELECT_TH    = 93  # 93%+ = ×‘×—×™×¨×” ××•×˜×•××˜×™×ª
MIN_SCORE_DISPLAY = 70
MAX_DISPLAYED     = 3   # ğŸ”¥ ×©×•× ×” ×-6 ×œ-3 ×¢×‘×•×¨ 93%+

# ğŸ”¥ ×¡×“×¨ ×¢×“×™×¤×•×ª ×œ×©×“×•×ª ×‘×¤×¨×•×¤×™×œ ××•×–××Ÿ
FIELD_PRIORITY = {
    '×¦×“': ['×¦×“', 'side', '×—×ª×Ÿ', '×›×œ×”', 'groom', 'bride'],
    '×§×‘×•×¦×”': ['×§×‘×•×¦×”', 'group', '××©×¤×—×”', '×—×‘×¨×™×', '×¢×‘×•×“×”', 'family', 'friends', 'work'],
    '×›××•×ª ××•×–×× ×™×': ['×›××•×ª', 'quantity', '××•×–×× ×™×', '××•×¨×—×™×', 'guests', '×›××•×ª ××•×–×× ×™×'],
    '×›×ª×•×‘×ª': ['×›×ª×•×‘×ª', 'address', '×¢×™×¨', '×¨×—×•×‘', 'city', 'street'],
    '×©×•×œ×—×Ÿ': ['×©×•×œ×—×Ÿ', 'table', '××¡×¤×¨ ×©×•×œ×—×Ÿ', 'table number'],
    '×”×¢×¨×•×ª': ['×”×¢×¨×•×ª', 'notes', 'comments', '××™×“×¢', '×”×¢×¨×”', 'info', 'note']
}

# ×”×¨×©××•×ª/Scopes ×œ×§×¨×™××” ×‘×œ×‘×“
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets.readonly",
    "https://www.googleapis.com/auth/drive.readonly",
]

# ENV ×œ×’×™×œ×™×•×Ÿ ×”××•×¨×©×™×
SPREADSHEET_ID_ENV  = "SPREADSHEET_ID"
WORKSHEET_TITLE_ENV = "WORKSHEET_TITLE"

# ×’×™×‘×•×™ ××§×•××™
LOCAL_ALLOWED_FILE  = "allowed_users.xlsx"
LOCAL_PHONE_COLS    = ("×˜×œ×¤×•×Ÿ", "phone", "××¡×¤×¨", "××¡×¤×¨ ×¤×œ××¤×•×Ÿ", "×¤×œ××¤×•×Ÿ")

# ğŸ”¥ ××™×œ×•×ª ×™×—×¡/×§×©×¨ (ignored ×œ×’××¨×™)
GENERIC_TOKENS: Set[str] = {"×©×œ", "×”", "×‘×Ÿ", "×‘×ª", "××©×¤×—×ª", "××—×™", "××—×•×ª", "×“×•×“", "×“×•×“×”"}

# ğŸ”¥ ×¡×™×•××•×ª/×›×™× ×•×™×™× ×©××™× × ×—×œ×§ ××”×©× (× ××—×§×•×ª ××”×§×¦×”)
SUFFIX_TOKENS: Set[str] = {
    "××™×œ×•××™×", "miluyim", "miloyim", "mil", "× ×™×™×“", "×¡×œ×•×œ×¨", "×¡×œ×•×œ×¨×™",
    "×‘×™×ª", "×¢×‘×•×“×”", "×¢×¡×§×™", "××™×©×™", "××©×¨×“"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ×¢×–×¨×™× ×‘×¡×™×¡×™×™× â”€â”€â”€â”€â”€â”€â”€â”€â”€
def only_digits(s: str) -> str:
    """××—×–×™×¨ ×¨×§ ×¡×¤×¨×•×ª ××”××—×¨×•×–×ª"""
    return re.sub(r"\D+", "", s or "")

# ×›×œ ×¤×™×¡×•×§ + ×ª×•×•×™ ×€ / () [] ×™×—×œ×¤×• ×œ×¨×•×•×— (× ×•×¨××œ×™×–×¦×™×” ××©×•×¤×¨×ª)
_punc_re   = re.compile(r"[\|\\/()\[\]\"'×³×´.,\-]+")
_space_re  = re.compile(r"\s+")
_token_re  = re.compile(r"\s+")

def normalize(txt: str | None) -> str:
    """× ×™×¨××•×œ ××©×•×¤×¨: lowercase â†’ ×”×•×¨×“×ª ×¡×™×× ×™ ×¤×™×¡×•×§ â†’ ×¨×•×•×— ×™×—×™×“ â†’ ×ª×¢×ª×™×§ ×œ×˜×™× ×™."""
    if not txt:
        return ""
    t = str(txt).lower()
    t = _punc_re.sub(" ", t)
    t = _space_re.sub(" ", t).strip()
    return unidecode.unidecode(t)

# ğŸ”¥ × ×™×§×•×™ ×˜×•×§× ×™× ××ª×§×“×
def _clean_token(tok: str) -> str:
    """××¡×™×¨ ×•' ×—×™×‘×•×¨, ×¡×™×•××ª i, ×•××ª×¢×œ× ×Ö¾SUFFIX_TOKENS"""
    if tok in SUFFIX_TOKENS:
        return ""
    # ×”×¡×¨×ª ×•' ×—×™×‘×•×¨: "×•×“×•×“" â†’ "×“×•×“"
    if tok.startswith("v") and len(tok) > 2:
        tok = tok[1:]
    # ×”×¡×¨×ª ×¡×™×•××ª i: "davidi" â†’ "david"
    if len(tok) >= 4 and tok.endswith("i"):
        tok = tok[:-1]
    return tok

def _tokens(name: str) -> List[str]:
    """××—×–×™×¨ ×¨×©×™××ª ×˜×•×§× ×™× × ×§×™×™×” ××—×¨×™ ×¡×™× ×•×Ÿ ××™×œ×™× ×’× ×¨×™×•×ª ×•×¡×™×•××•×ª"""
    tks = [_clean_token(t) for t in _token_re.split(name)]
    return [t for t in tks if t and t not in GENERIC_TOKENS]

# ğŸ”¥ Fuzzy Equality (Levenshtein â‰¥ 90%)
def _fuzzy_eq(a: str, b: str) -> bool:
    """×˜×•×§× ×™× ×–×”×™× ××• ×“×•××™× â‰¥ 90 % ×‘â€‘Levenshtein"""
    return a == b or distance.Levenshtein.normalized_similarity(a, b) >= 0.9

# ğŸ”¥ Fuzzy Jaccard
def _fuzzy_jaccard(gs: List[str], cs: List[str]) -> float:
    """×—×™×©×•×‘ Jaccard ×¢× ×”×ª×—×©×‘×•×ª ×‘-fuzzy equality"""
    matched, used = 0, set()
    for g in gs:
        for c in cs:
            if c in used:
                continue
            if _fuzzy_eq(g, c):
                matched += 1
                used.add(c)
                break
    union = len(set(gs)) + len(set(cs)) - matched
    return matched / union if union else 1.0

def format_phone(ph: str) -> str:
    """×¢×™×¦×•×‘ ×˜×œ×¤×•×Ÿ: 972 -> 0, ×¤×•×¨××˜ XXX-XXXXXXX"""
    d = "".join(filter(str.isdigit, str(ph)))
    if d.startswith("972"):
        d = "0" + d[3:]
    return f"{d[:3]}-{d[3:]}" if len(d) == 10 else d

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×¢××•×“×•×ª ×¢× ×©×™×¤×•×¨×™× â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_column_type(col_name: str, sample_data: pd.Series) -> str:
    """×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×¡×•×’ ×”×¢××•×“×” ×œ×¤×™ ×©× ×•×ª×•×›×Ÿ"""
    col_lower = str(col_name).lower().strip()
    
    # ×‘×“×™×§×ª ×ª×•×›×Ÿ ×”×¢××•×“×”
    sample_str = sample_data.astype(str).str.lower()
    
    # ×¢××•×“×ª ×˜×œ×¤×•×Ÿ
    phone_keywords = ['×˜×œ×¤×•×Ÿ', '×¤×œ××¤×•×Ÿ', '× ×™×™×“', '×¡×œ×•×œ×¨', 'phone', 'mobile', 'cell', '××¡×¤×¨']
    has_phone_keyword = any(keyword in col_lower for keyword in phone_keywords)
    has_digits = sample_str.str.contains(r'\d{9,}').any()
    
    if has_phone_keyword or has_digits:
        return 'phone'
    
    # ×¢××•×“×ª ×©×
    name_keywords = ['×©×', 'name', '××•×–××Ÿ', 'guest', '××•×¨×—', '××©×ª×ª×£']
    has_name_keyword = any(keyword in col_lower for keyword in name_keywords)
    has_hebrew_letters = sample_str.str.contains(r'[×-×ª]').any()
    has_english_letters = sample_str.str.contains(r'[a-z]').any()
    
    if has_name_keyword or has_hebrew_letters or has_english_letters:
        return 'name'
    
    # ×¢××•×“×ª ×›××•×ª
    count_keywords = ['×›××•×ª', '××¡×¤×¨', '×§××•× ×˜', 'count', 'qty', 'quantity', '××•×¨×—×™×', '××•×–×× ×™×']
    has_count_keyword = any(keyword in col_lower for keyword in count_keywords)
    is_numeric = pd.to_numeric(sample_data, errors='coerce').notna().sum() > len(sample_data) * 0.7
    
    if has_count_keyword or is_numeric:
        return 'count'
    
    # ×¢××•×“×ª ×¦×“
    side_keywords = ['×¦×“', 'side', '×—×ª×Ÿ', '×›×œ×”', 'groom', 'bride']
    if any(keyword in col_lower for keyword in side_keywords):
        return 'side'
    
    # ×¢××•×“×ª ×§×‘×•×¦×”
    group_keywords = ['×§×‘×•×¦×”', 'group', '×¡×•×’', 'type', '×§×˜×’×•×¨×™×”', 'category', '×™×—×¡', 'relation', '××©×¤×—×”', '×—×‘×¨×™×', '×¢×‘×•×“×”']
    if any(keyword in col_lower for keyword in group_keywords):
        return 'group'
    
    return 'other'

def smart_column_mapping(df: pd.DataFrame) -> Dict[str, str]:
    """××™×¤×•×™ ×—×›× ×©×œ ×¢××•×“×•×ª ×œ×¤×™ ×ª×•×›×Ÿ ×•×©×"""
    mapping = {}
    
    for col in df.columns:
        col_type = detect_column_type(col, df[col].head(10))
        mapping[col] = col_type
    
    return mapping

def identify_relevant_fields(df: pd.DataFrame) -> Dict[str, str]:
    """×–×™×”×•×™ ×”×©×“×•×ª ×”×¨×œ×•×•× ×˜×™×™× ×‘×™×•×ª×¨ ×œ×ª×¦×•×’×”"""
    column_mapping = smart_column_mapping(df)
    relevant_fields = {}
    
    # ×—×¤×© ×¦×“
    side_cols = [col for col, type_val in column_mapping.items() if type_val == 'side']
    if side_cols:
        relevant_fields['×¦×“'] = side_cols[0]
    
    # ×—×¤×© ×§×‘×•×¦×”
    group_cols = [col for col, type_val in column_mapping.items() if type_val == 'group']
    if group_cols:
        relevant_fields['×§×‘×•×¦×”'] = group_cols[0]
    
    # ×—×¤×© ×›××•×ª
    count_cols = [col for col, type_val in column_mapping.items() if type_val == 'count']
    if count_cols:
        relevant_fields['×›××•×ª'] = count_cols[0]
    
    return relevant_fields

# ğŸ”¥ ×–×™×”×•×™ ×©× ××œ× ×—×›× (×©× ×¤×¨×˜×™ + ××©×¤×—×”)
def _resolve_full_name_series(df: pd.DataFrame) -> pd.Series:
    """
    ×××—×“ ×©× ×¤×¨×˜×™+××©×¤×—×” / ××–×”×” '×©× ××œ×' / ×“××•×™×•×ª ×©× â€“ ×•××—×–×™×¨ Series.
    ××œ×’×•×¨×™×ª× ××ª×§×“× ×œ×–×™×”×•×™ ×•×—×™×‘×•×¨ ×¢××•×“×•×ª ×©×.
    """
    cols = list(df.columns)
    low = {c: str(c).strip().lower() for c in cols}
    
    # ×–×™×”×•×™ ×™×©×™×¨ ×©×œ ×¢××•×“×ª ×©× ××œ×
    direct = {"×©× ××œ×", "full name", "fullname", "guest name", "×©× ×”××•×–××Ÿ", "name"}
    for c in cols:
        if low[c] in direct:
            return df[c].fillna("").astype(str).str.strip()
    
    # ×—×™×‘×•×¨ ×©× ×¤×¨×˜×™ + ××©×¤×—×”
    first = [c for c in cols if "×¤×¨×˜×™" in low[c] or low[c] in {"×©×", "first", "firstname", "given"}]
    last  = [c for c in cols if "××©×¤×—×”" in low[c] or low[c] in {"last", "lastname", "surname", "family"}]
    
    if first and last:
        f = first[0]
        l = last[0]
        return (df[f].fillna("").astype(str).str.strip() + " " +
                df[l].fillna("").astype(str).str.strip()).str.replace(r"\s+", " ", regex=True).str.strip()
    
    # ×—×™×¤×•×© ×¢××•×“×•×ª ×“××•×™×•×ª ×©×
    name_like = [c for c in cols if any(k in low[c] for k in ["×©×", "name", "guest", "××•×–××Ÿ"])]
    if name_like:
        best_col = max(name_like, key=lambda col: df[col].astype(str).str.len().mean())
        return df[best_col].fillna("").astype(str).str.strip()
    
    # ×× ×œ× ××¦×× ×• ×›×œ×•× - ×”×©×ª××© ×‘×¢××•×“×” ×”×¨××©×•× ×”
    if len(df.columns) > 0:
        return df.iloc[:, 0].fillna("").astype(str).str.strip()
    
    return pd.Series([""] * len(df))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ×˜×¢×™× ×ª ×§×‘×¦×™× ×’××™×©×” ×¢× ×©×™×¤×•×¨×™× â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_excel_flexible(file) -> pd.DataFrame:
    """×˜×¢×™× ×ª ×§×•×‘×¥ ×¢× ×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×¢××•×“×•×ª ×•×˜×™×¤×•×œ ×‘×¤×•×¨××˜×™× ×©×•× ×™×"""
    try:
        print(f"ğŸ“ Attempting to read file: {getattr(file, 'filename', 'unknown')}")
        
        # ×§×¨×™××ª ×”×§×•×‘×¥
        if hasattr(file, "filename") and str(file.filename).lower().endswith(".csv"):
            df = pd.read_csv(file, encoding='utf-8')
        else:
            df = pd.read_excel(file)
        
        print(f"ğŸ“Š Raw file data - Shape: {df.shape}")
        print(f"ğŸ“‹ Original columns: {list(df.columns)}")
        
        # × ×™×§×•×™ ×©××•×ª ×¢××•×“×•×ª
        df.columns = [str(col).strip() for col in df.columns]
        df = df.dropna(how='all')
        
        if len(df) == 0:
            raise Exception("×”×§×•×‘×¥ ×¨×™×§ ××• ×œ× ××›×™×œ × ×ª×•× ×™×")
        
        # ×–×™×”×•×™ ×× ×–×” ×§×•×‘×¥ ×× ×©×™ ×§×©×¨ ×¢× ×”×¤×•×¨××˜ ×”×§×‘×•×¢
        is_contacts_file = (
            len(df.columns) >= 3 and 
            df.iloc[:, 0].astype(str).str.contains(r'972\d{9}').any()
        )
        
        # ×™×¦×™×¨×ª ×¢××•×“×•×ª ×¡×˜× ×“×¨×˜×™×•×ª
        standard_df = pd.DataFrame()
        
        if is_contacts_file:
            print("ğŸ“ Detected contacts file with fixed format")
            standard_df[PHONE_COL] = df.iloc[:, 0].astype(str).str.strip()
            standard_df[NAME_COL] = df.iloc[:, 2].astype(str).str.strip()
        else:
            print("ğŸ‘° Detected guests file - using flexible detection")
            column_mapping = smart_column_mapping(df)
            relevant_fields = identify_relevant_fields(df)
            
            # ğŸ”¥ ×©×™××•×© ×‘××œ×’×•×¨×™×ª× ×”×—×›× ×œ×–×™×”×•×™ ×©×
            standard_df[NAME_COL] = _resolve_full_name_series(df)
            
            # ×¢××•×“×ª ×˜×œ×¤×•×Ÿ (××•×¤×¦×™×•× ×œ×™×ª ×œ××•×–×× ×™×)
            phone_cols = [col for col, type_val in column_mapping.items() if type_val == 'phone']
            if phone_cols:
                standard_df[PHONE_COL] = df[phone_cols[0]].astype(str).str.strip()
            else:
                standard_df[PHONE_COL] = ""
            
            # ğŸ”¥ ×—×™×œ×•×¥ ×›××•×ª ××˜×§×¡×˜
            count_cols = [col for col, type_val in column_mapping.items() if type_val == 'count']
            if count_cols:
                counts_raw = df[count_cols[0]].astype(str)
                counts_num = pd.to_numeric(
                    counts_raw.str.extract(r"(\d+)")[0], 
                    errors="coerce"
                )
                standard_df[COUNT_COL] = counts_num.fillna(1).astype(int)
            else:
                standard_df[COUNT_COL] = 1
            
            # ×©×“×•×ª × ×•×¡×¤×™×
            for display_name, col_name in relevant_fields.items():
                if col_name in df.columns:
                    standard_df[display_name] = df[col_name].astype(str).fillna("")
        
        # ×©×“×•×ª ×—×•×‘×”
        if COUNT_COL not in standard_df.columns:
            standard_df[COUNT_COL] = 1
        if SIDE_COL not in standard_df.columns:
            standard_df[SIDE_COL] = ""
        if GROUP_COL not in standard_df.columns:
            standard_df[GROUP_COL] = ""
        
        # × ×™×¨××•×œ ×©××•×ª
        standard_df["norm_name"] = standard_df[NAME_COL].map(normalize)
        
        # ×¡×™× ×•×Ÿ ×¨×©×•××•×ª ×¨×™×§×•×ª
        standard_df = standard_df[standard_df["norm_name"].str.strip() != ""]
        
        if len(standard_df) == 0:
            raise Exception("×œ× × ××¦××• ×¨×©×•××•×ª ×ª×§×™× ×•×ª ×¢× ×©××•×ª")
        
        print(f"âœ… Processing complete! Final shape: {standard_df.shape}")
        return standard_df
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        raise Exception(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥: {str(e)}")

def load_mobile_contacts(contacts_data: List[Dict]) -> pd.DataFrame:
    """×˜×¢×™× ×ª ×× ×©×™ ×§×©×¨ ×××•×‘×™×™×œ"""
    try:
        print(f"ğŸ“± Loading mobile contacts: {len(contacts_data)} contacts")
        
        df = pd.DataFrame(contacts_data)
        
        if 'name' not in df.columns or 'phone' not in df.columns:
            raise Exception("×¤×•×¨××˜ ×× ×©×™ ×§×©×¨ ×œ× ×ª×§×™×Ÿ")
        
        standard_df = pd.DataFrame()
        standard_df[NAME_COL] = df['name'].astype(str).str.strip()
        standard_df[PHONE_COL] = df['phone'].astype(str).str.strip()
        standard_df[COUNT_COL] = 1
        standard_df[SIDE_COL] = ""
        standard_df[GROUP_COL] = ""
        standard_df["norm_name"] = standard_df[NAME_COL].map(normalize)
        
        standard_df = standard_df[
            (standard_df["norm_name"].str.strip() != "") & 
            (standard_df[PHONE_COL].str.strip() != "")
        ]
        
        if len(standard_df) == 0:
            raise Exception("×œ× × ××¦××• ×× ×©×™ ×§×©×¨ ×ª×§×™× ×™×")
        
        print(f"âœ… Mobile contacts processed! Final count: {len(standard_df)}")
        return standard_df
        
    except Exception as e:
        print(f"âŒ Error processing mobile contacts: {e}")
        raise Exception(f"×œ× × ×™×ª×Ÿ ×œ×¢×‘×“ ××ª ×× ×©×™ ×”×§×©×¨: {str(e)}")

def create_contacts_template() -> pd.DataFrame:
    """×™×•×¦×¨ ×§×•×‘×¥ ×“×•×’××” ×œ×× ×©×™ ×§×©×¨"""
    template = pd.DataFrame({
        '××¡×¤×¨ × ×™×™×“': [
            '972507676706',
            '972503377313',
            '972545221212',
            '972508688680'
        ],
        '×©×': [
            '× ×™×¨',
            '×›×¨×™×¡×˜×™× ×”',
            '×¦',
            '×××™×¨'
        ],
        '×©× ××œ×': [
            '× ×™×¨ ×œ×•×™',
            '×›×¨×™×¡×˜×™× ×” ×”×¥',
            '×¦ ×××™ ××“×××™×‘×ª ×‘×™×¡×œ×”',
            '×××™×¨ ××¨×“×›×™ ×§×•×§×˜×œ×™×'
        ]
    })
    return template

def create_guests_template() -> pd.DataFrame:
    """×™×•×¦×¨ ×§×•×‘×¥ ×“×•×’××” ×œ××•×–×× ×™×"""
    template = pd.DataFrame({
        '×©× ××œ×': [
            '×™×©×¨××œ ×›×”×Ÿ',
            '×©×¨×” ×œ×•×™', 
            '×“×•×“ ××‘×¨×”×',
            '×¨×—×œ ×’×•×œ×“'
        ],
        '×›××•×ª ××•×–×× ×™×': [2, 1, 3, 2],
        '×¦×“': ['×—×ª×Ÿ', '×›×œ×”', '×—×ª×Ÿ', '×›×œ×”'],
        '×§×‘×•×¦×”': ['××©×¤×—×”', '×—×‘×¨×•×ª', '×¢×‘×•×“×”', '××©×¤×—×”']
    })
    return template

def load_excel(file) -> pd.DataFrame:
    """×˜×•×¢×Ÿ CSV/XLSX ×¢× ×–×™×”×•×™ ××•×˜×•××˜×™ (backwards compatibility)"""
    return load_excel_flexible(file)

# ğŸ”¥ ××œ×’×•×¨×™×ª× ×”×ª×××” ××©×•×¤×¨ (3 ×¨×›×™×‘×™× ××©×•×§×œ×œ×™×)
def full_score(g_norm: str, c_norm: str) -> int:
    """×¦×™×•×Ÿ ×”×ª×××” 0â€“100 ×¢× ××œ×’×•×¨×™×ª× ××ª×§×“×"""
    if not g_norm or not c_norm:
        return 0
    if g_norm.strip() == c_norm.strip():
        return AUTO_SCORE
        
    g_t, c_t = _tokens(g_norm), _tokens(c_norm)
    
    if g_t == c_t:
        return AUTO_SCORE
    
    if not g_t or not c_t:
        return fuzz.partial_ratio(g_norm, c_norm)
    
    tr = fuzz.token_set_ratio(" ".join(g_t), " ".join(c_t)) / 100
    fr = fuzz.ratio(g_t[0], c_t[0]) / 100
    jr = _fuzzy_jaccard(g_t, c_t)
    
    gap = abs(len(g_t) - len(c_t))
    penalty = (min(len(g_t), len(c_t)) / max(len(g_t), len(c_t))) if gap >= 2 else 1
    
    score = (0.6 * tr + 0.2 * fr + 0.2 * jr) * penalty * 100
    return int(round(score))

def reason_for(g_norm: str, c_norm: str, score: int) -> str:
    """××—×–×™×¨ ×”×¡×‘×¨ ×§×¦×¨ ×œ××” × ×™×ª×Ÿ ×”×¦×™×•×Ÿ"""
    overlap = [t for t in _tokens(g_norm) if t in set(_tokens(c_norm))]
    if overlap:
        return f"×—×¤×™×¤×”: {', '.join(overlap[:2])}"
    if score >= AUTO_SELECT_TH:
        return "×”×ª×××” ×’×‘×•×”×”"
    return ""

def to_buf(df: pd.DataFrame) -> BytesIO:
    """×™×™×¦×•× ×œ-Excel: ××¡×™×¨ ×¢××•×“×•×ª ×¤× ×™××™×•×ª"""
    export = df.drop(
        columns=["norm_name", "score", "best_score"], 
        errors="ignore"
    ).copy()
    
    if PHONE_COL in export.columns:
        cols = [col for col in export.columns if col != PHONE_COL]
        cols.append(PHONE_COL)
        export = export[cols]
    
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as w:
        export.to_excel(w, index=False, sheet_name="×ª×•×¦××•×ª")
    buf.seek(0)
    return buf

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ××¢×¨×›×ª ×”×ª×××•×ª ××ª×§×“××ª â”€â”€â”€â”€â”€â”€â”€â”€â”€
def top_matches(guest_norm: str, contacts_df: pd.DataFrame, limit_to_three: bool = False) -> pd.DataFrame:
    """
    ğŸ”¥ ×‘×—×™×¨×ª ××•×¢××“×™× ×”×˜×•×‘×™× ×‘×™×•×ª×¨ ×¢× ×‘×—×™×¨×” ××•×˜×•××˜×™×ª ×‘-93%+
    ğŸ”¥ limit_to_three=True â†’ ×¨×§ 3 ×ª×•×¦××•×ª ×¢×‘×•×¨ 93%+
    """
    if not guest_norm:
        return pd.DataFrame(columns=list(contacts_df.columns) + ["score", "reason"])

    scores = contacts_df["norm_name"].apply(lambda c: full_score(guest_norm, c))
    df = contacts_df.assign(score=scores)

    max_score = int(df["score"].max())
    
    # ğŸ”¥ ×× ×”×ª×××” ××•×©×œ××ª ××• 93%+ â†’ ×”×’×‘×œ ×œ-3 ××•×¢××“×™× >= 90
    if limit_to_three and max_score >= AUTO_SELECT_TH:
        candidates = (
            df[df["score"] >= 90]
            .sort_values(["score", NAME_COL], ascending=[False, True])
            .head(3)  # ğŸ”¥ ×¨×§ 3!
            .copy()
        )
    elif max_score == AUTO_SCORE:
        candidates = (
            df[df["score"] >= 90]
            .sort_values(["score", NAME_COL], ascending=[False, True])
            .head(3)
            .copy()
        )
    else:
        candidates = (
            df[df["score"] >= MIN_SCORE_DISPLAY]
            .sort_values(["score", NAME_COL], ascending=[False, True])
            .head(MAX_DISPLAYED)
            .copy()
        )

    if len(candidates) > 0:
        reason_series = candidates.apply(
            lambda row: reason_for(guest_norm, row["norm_name"], row["score"]),
            axis=1
        )
        candidates = candidates.copy()
        candidates["reason"] = reason_series

    return candidates

# ğŸ”¥ ×—×™×œ×•×¥ ×¤×¨×˜×™ ××•×–××Ÿ ×¨×œ×•×•× ×˜×™×™× - ×—×›×!
def extract_smart_fields(guest_details: dict) -> dict:
    """
    ğŸ”¥ ×—×™×œ×•×¥ ×—×›× ×©×œ ×©×“×•×ª ×œ×¤×™ ×¡×“×¨ ×¢×“×™×¤×•×ª
    ××—×–×™×¨ ×¨×§ ×©×“×•×ª ×©× ××¦××• ×‘×§×•×‘×¥
    """
    result = {}
    
    for display_name, keywords in FIELD_PRIORITY.items():
        for key in guest_details.keys():
            key_lower = key.lower()
            if any(kw in key_lower for kw in keywords):
                value = guest_details[key]
                if value and str(value).strip():
                    result[display_name] = str(value).strip()
                break
    
    return result

def extract_relevant_guest_details(row: pd.Series) -> Dict:
    """×—×™×œ×•×¥ ×¨×§ ×”×¤×¨×˜×™× ×”×¨×œ×•×•× ×˜×™×™× ×©×œ ××•×–××Ÿ"""
    details = {}
    
    exclude_cols = {NAME_COL, PHONE_COL, "norm_name", "score", "best_score"}
    
    for col in row.index:
        if col not in exclude_cols and pd.notna(row[col]) and str(row[col]).strip():
            details[col] = str(row[col])
    
    return details

def compute_best_scores(guests_df: pd.DataFrame, contacts_df: pd.DataFrame) -> pd.DataFrame:
    """××—×©×‘ ××ª ×”×¦×™×•×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×œ×›×œ ××•×–××Ÿ"""
    best_scores = []
    
    for _, guest_row in guests_df.iterrows():
        matches = top_matches(guest_row["norm_name"], contacts_df)
        best_score = int(matches["score"].max()) if len(matches) > 0 else 0
        best_scores.append(best_score)
    
    guests_df = guests_df.copy()
    guests_df["best_score"] = best_scores
    return guests_df

# ğŸ”¥ ×¤×•× ×§×¦×™×” ××¨×›×–×™×ª ×œ×¢×™×‘×•×“ ×”×ª×××•×ª - ××©×•×“×¨×’×ª!
def process_matching_results(guests_df: pd.DataFrame, contacts_df: pd.DataFrame, contacts_source: str = "file") -> List[Dict]:
    """
    ğŸ”¥ ×¢×™×‘×•×“ ××œ× ×¢× ××™×•×Ÿ ×—×›×:
    1. ×§×•×“× ×›×œ ×”×”×ª×××•×ª ×”××•×©×œ××•×ª (100%) - ×¢×“ 30
    2. ××—×¨ ×›×š ×”×ª×××•×ª ×’×‘×•×”×•×ª (93-99%)
    3. ××—×¨ ×›×š ×˜×•×‘×•×ª (70-92%)
    4. ×‘×¡×•×£ ×—×œ×©×•×ª (<70)
    
    ğŸ”¥ ×ª×™×§×•× ×™×:
    - ××™×—×•×“ ×›×¤×•×œ×™× (××•×ª×• ××¡×¤×¨ ×˜×œ×¤×•×Ÿ)
    - ×‘×—×™×¨×” ××•×˜×•××˜×™×ª ×©×œ ×”×’×‘×•×” ×‘×™×•×ª×¨ ××¢×œ 93%
    - ×¤×•×¨××˜ ×ª×¦×•×’×”: ×©× | ×˜×œ×¤×•×Ÿ | ××—×•×–
    """
    results = []
    
    # ×—×©×‘ ×¦×™×•× ×™× ××§×¡×™××œ×™×™×
    guests_with_scores = compute_best_scores(guests_df, contacts_df)
    
    # ğŸ”¥ ××™×•×Ÿ ×—×›× - 100% ×¨××©×•×Ÿ!
    perfect_matches = []
    auto_matches = []
    good_matches = []
    weak_matches = []
    
    for _, guest_row in guests_with_scores.iterrows():
        guest_name = guest_row[NAME_COL]
        guest_norm = guest_row["norm_name"]
        best_score = guest_row["best_score"]
        
        # ×§×‘×™×¢×” ×× ×œ×”×’×‘×™×œ ×œ-3 ×ª×•×¦××•×ª
        limit_to_three = best_score >= AUTO_SELECT_TH
        
        # ××¦× ××•×¢××“×™×
        matches = top_matches(guest_norm, contacts_df, limit_to_three=limit_to_three)
        
        # ğŸ”¥ ××™×—×•×“ ×›×¤×•×œ×™× - ××•×ª×• ××¡×¤×¨ ×˜×œ×¤×•×Ÿ
        phone_map = {}
        
        for _, match_row in matches.iterrows():
            phone = format_phone(match_row[PHONE_COL])
            score = int(match_row["score"])
            name = match_row[NAME_COL]
            reason = match_row.get("reason", "")
            
            if phone not in phone_map:
                phone_map[phone] = {
                    "names": [name],
                    "phone": phone,
                    "score": score,
                    "reason": reason
                }
            else:
                # ×”×•×¡×£ ×©× × ×•×¡×£
                phone_map[phone]["names"].append(name)
                # ×¢×“×›×Ÿ ×¦×™×•×Ÿ ×× ×’×‘×•×” ×™×•×ª×¨
                if score > phone_map[phone]["score"]:
                    phone_map[phone]["score"] = score
                    phone_map[phone]["reason"] = reason
        
        # ×”××¨ ×œ×¨×©×™××ª ××•×¢××“×™×
        candidates = []
        for phone, data in phone_map.items():
            candidate = {
                "name": " / ".join(data["names"]),  # ğŸ”¥ ××™×—×•×“ ×©××•×ª ×¢× /
                "phone": phone,
                "score": data["score"],
                "reason": data["reason"]
            }
            candidates.append(candidate)
        
        # ğŸ”¥ ××™×•×Ÿ ×œ×¤×™ ×¦×™×•×Ÿ (××”×’×‘×•×” ×œ× ××•×š)
        candidates.sort(key=lambda x: x["score"], reverse=True)
        
        # ğŸ”¥ ×‘×—×™×¨×” ××•×˜×•××˜×™×ª - ×ª××™×“ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×× >= 93%
        auto_selected = None
        if candidates and candidates[0]["score"] >= AUTO_SELECT_TH:
            auto_selected = candidates[0]
        
        # ğŸ”¥ ×—×™×œ×•×¥ ×—×›× ×©×œ ×¤×¨×˜×™ ××•×–××Ÿ
        raw_details = extract_relevant_guest_details(guest_row)
        guest_details = extract_smart_fields(raw_details)
        
        result = {
            "guest": guest_name,
            "guest_details": guest_details,
            "candidates": candidates,
            "best_score": best_score,
            "auto_selected": auto_selected
        }
        
        # ğŸ”¥ ×¡×™×•×•×’ ×œ×¤×™ ×¦×™×•×Ÿ
        if best_score == 100:
            perfect_matches.append(result)
        elif best_score >= AUTO_SELECT_TH:
            auto_matches.append(result)
        elif best_score >= 70:
            good_matches.append(result)
        else:
            weak_matches.append(result)
    
    # ğŸ”¥ ××™×–×•×’ ×¢× ×”×’×‘×œ×” ×©×œ 30 ××•×©×œ××™×
    sorted_results = perfect_matches[:30] + auto_matches + good_matches + weak_matches
    
    return sorted_results

# logic.py - × ×•×¡×™×£ ×¤×•× ×§×¦×™×” ×œ×‘×“×™×§×ª ×ª×§×™× ×•×ª
def validate_dataframes(guests_df: pd.DataFrame, contacts_df: pd.DataFrame) -> tuple[bool, str]:
    """×‘×•×“×§ ×©×”-DataFrames ×ª×§×™× ×™× ×œ×¤× ×™ ×¢×™×‘×•×“"""
    
    if guests_df is None or len(guests_df) == 0:
        return False, "×§×•×‘×¥ ×”××•×–×× ×™× ×¨×™×§ ××• ×œ× ×ª×§×™×Ÿ"
    
    if NAME_COL not in guests_df.columns:
        return False, f"×—×¡×¨×” ×¢××•×“×” '{NAME_COL}' ×‘×§×•×‘×¥ ×”××•×–×× ×™×"
    
    if "norm_name" not in guests_df.columns:
        return False, "×©×’×™××ª ×¢×™×‘×•×“ - ×—×¡×¨×” × ×•×¨××œ×™×–×¦×™×” ×©×œ ×©××•×ª ××•×–×× ×™×"
    
    if contacts_df is None or len(contacts_df) == 0:
        return False, "×§×•×‘×¥ ×× ×©×™ ×”×§×©×¨ ×¨×™×§ ××• ×œ× ×ª×§×™×Ÿ"
    
    if NAME_COL not in contacts_df.columns:
        return False, f"×—×¡×¨×” ×¢××•×“×” '{NAME_COL}' ×‘×§×•×‘×¥ ×× ×©×™ ×”×§×©×¨"
    
    if PHONE_COL not in contacts_df.columns:
        return False, f"×—×¡×¨×” ×¢××•×“×” '{PHONE_COL}' ×‘×§×•×‘×¥ ×× ×©×™ ×”×§×©×¨"
    
    if "norm_name" not in contacts_df.columns:
        return False, "×©×’×™××ª ×¢×™×‘×•×“ - ×—×¡×¨×” × ×•×¨××œ×™×–×¦×™×” ×©×œ ×©××•×ª ×× ×©×™ ×§×©×¨"
    
    return True, "OK"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ××¢×¨×›×ª ×”×¨×©××•×ª: Google Sheets + ×§×•×‘×¥ ×’×™×‘×•×™ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _pick_worksheet(sh):
    """×××ª×¨ ×œ×©×•× ×™×ª ×œ×¤×™ ×©×"""
    wanted = os.getenv(WORKSHEET_TITLE_ENV)
    if wanted:
        w = wanted.strip().lower()
        for ws in sh.worksheets():
            if (ws.title or "").strip().lower() == w:
                return ws
    return sh.get_worksheet(0)

def _find_phone_col(header: list[str]) -> int:
    """××™× ×“×§×¡ ×¢××•×“×ª ×”×˜×œ×¤×•×Ÿ ×œ×¤×™ ×›×•×ª×¨×ª"""
    header_lower = [str(h).strip().lower() for h in header]
    lookup = tuple(x.lower() for x in ("×˜×œ×¤×•×Ÿ", "××¡×¤×¨ ×¤×œ××¤×•×Ÿ", "×¤×œ××¤×•×Ÿ", "phone", "××¡×¤×¨"))
    for i, h in enumerate(header_lower):
        if h in lookup:
            return i
    return 1

def _load_allowed_from_sheets() -> set[str] | None:
    """×˜×•×¢×Ÿ ×¡×˜ ×˜×œ×¤×•× ×™× ××•×¨×©×™× ×-Sheets"""
    if not GOOGLE_AVAILABLE:
        logging.info("Google Sheets not available - skipping")
        return None
        
    sheet_id = os.getenv(SPREADSHEET_ID_ENV)
    if not sheet_id:
        return None
    try:
        creds, _ = google.auth.default(scopes=SCOPES)
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(sheet_id)
        ws = _pick_worksheet(sh)

        rows = ws.get_all_values() or []
        if len(rows) < 2:
            logging.info("Allowed sheet is empty or header-only.")
            return set()

        header = [str(c).strip() for c in rows[0]]
        phone_idx = _find_phone_col(header)

        allowed = {
            only_digits(r[phone_idx])
            for r in rows[1:]
            if len(r) > phone_idx and only_digits(r[phone_idx])
        }

        if allowed:
            logging.info("Loaded %d allowed phones from Sheets.", len(allowed))
        else:
            logging.info("No allowed phones found in Sheets after normalization.")
        return allowed
    except Exception:
        logging.exception("Failed to load allowed phones from Sheets")
        return None

def _load_allowed_from_excel() -> set[str]:
    """×’×™×‘×•×™: ×˜×•×¢×Ÿ ×˜×œ×¤×•× ×™× ××•×¨×©×™× ×-allowed_users.xlsx"""
    if not os.path.exists(LOCAL_ALLOWED_FILE):
        return set()
    try:
        df = pd.read_excel(LOCAL_ALLOWED_FILE, dtype=str)
    except Exception:
        logging.exception("Failed to read local allowed Excel")
        return set()

    cols = [c for c in df.columns if any(k in str(c).lower() for k in LOCAL_PHONE_COLS)]
    if not cols:
        return set()

    phone_col = cols[0]
    allowed = {only_digits(str(v)) for v in df[phone_col] if only_digits(str(v))}
    logging.info("Loaded %d allowed phones from local Excel.", len(allowed))
    return allowed

def is_user_authorized(phone: str) -> bool:
    """True ×× ×”××¡×¤×¨ ××•×¤×™×¢ ×‘×¨×©×™××ª ×”××•×¨×©×™×"""
    clean = only_digits(phone)
    allowed = _load_allowed_from_sheets()
    if allowed is None:
        allowed = _load_allowed_from_excel()
    return clean in allowed